{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hi there!","text":"<p>I'm Rendy Bambang Junior.</p> <p>I am passionate in delivering value to the business using data and AI. 10+ years experience in data engineering, data science / AI, analytics, and software engineering. I like running. Recently tinkering responsible AI, as AI development pace is both exciting and scary!</p> <p>Currently writing a book, Praktis dbt and creating education content about data at Insinyur Data YouTube Channel.</p> <p>Open for collaboration, consultation, and mentoring. Reach me at  insinyur.data@gmail.com</p> <ul> <li> Blog</li> <li> LinkedIn</li> <li> Insinyur Data Channel</li> <li> Github</li> <li> X / Twitter</li> <li> Instagram</li> </ul>"},{"location":"#professional-experience","title":"Professional Experience","text":"<ul> <li>VP of Data, Evermos; Jakarta, ID. 2023 - present</li> <li>Big Data Lecturer (Industry), Bandung Institute of Technology (ITB). 2024 - present</li> <li>Head of Data, Ruangguru; Jakarta, ID. 2022 - 2023</li> <li>Senior Data Manager, Ruangguru; Jakarta, ID. 2019 - 2022</li> <li>Data Engineering Lead, Traveloka; Jakarta, ID. 2015 - 2019</li> <li>Software Engineer, Traveloka; Jakarta, ID. 2014 - 2015</li> <li>Project Management Office, Accenture; Jakarta, ID. 2013 - 2014</li> </ul>"},{"location":"#education","title":"Education","text":"<ul> <li>Georgia Institute of Technology, Atlanta, US. MSc CS ML. 2024, GPA 3.9 of 4.0</li> <li>Bandung Institute of Technology, Bandung, ID. BE Informatics, 2009 - 2013, GPA 3.9 of 4.0</li> </ul>"},{"location":"#awards-and-certificate","title":"Awards and Certificate","text":"<ul> <li>Exceptional Department Rating - Evermos, 2024</li> <li>CHIEF of The Year - Ruangguru, 2021</li> <li>Most Inspiring Award - Data Team Traveloka, 2019</li> <li>AWS Certified SysOps Administrator Associate, 2016</li> <li>2<sup>nd</sup> Place Best Student, Informatics Eng, Bandung Institute of Technology, 2012</li> <li>Bronze Medal, Programming Competition, National Science Olympiad, 2008 </li> <li>3<sup>rd</sup> Place, National Programming Competition IPB, 2008 </li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>Google Developer Expert, AI and Cloud, 2019 - present</li> <li>Mentor at Google Startup Accelerator Indonesia and SouthEast Asia, 2022 - present</li> </ul>"},{"location":"blog/","title":"Rendy's Blog","text":""},{"location":"blog/tags/","title":"Tags","text":""},{"location":"blog/tags/#tag:airflow","title":"airflow","text":"<ul> <li>            A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer          </li> <li>            Analyze Jira Issues using BigQuery and Data Studio          </li> </ul>"},{"location":"blog/tags/#tag:architecture","title":"architecture","text":"<ul> <li>            Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?          </li> </ul>"},{"location":"blog/tags/#tag:bakauheni","title":"bakauheni","text":"<ul> <li>            Lampung Road Trip: Perjalanan dari Jakarta ke Bandar Lampung naik Ferry Merak - Bakauheni          </li> </ul>"},{"location":"blog/tags/#tag:bigquery","title":"bigquery","text":"<ul> <li>            A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer          </li> <li>            Analyze Jira Issues using BigQuery and Data Studio          </li> </ul>"},{"location":"blog/tags/#tag:composer","title":"composer","text":"<ul> <li>            A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer          </li> <li>            Analyze Jira Issues using BigQuery and Data Studio          </li> </ul>"},{"location":"blog/tags/#tag:computer-science","title":"computer science","text":"<ul> <li>            Kuliah S2 Computer Science Online di Georgia Institute of Technology          </li> </ul>"},{"location":"blog/tags/#tag:data-modeling","title":"data-modeling","text":"<ul> <li>            Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?          </li> </ul>"},{"location":"blog/tags/#tag:dimensonal-modeling","title":"dimensonal-modeling","text":"<ul> <li>            Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?          </li> </ul>"},{"location":"blog/tags/#tag:event-sourcing","title":"event-sourcing","text":"<ul> <li>            Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?          </li> </ul>"},{"location":"blog/tags/#tag:ferry","title":"ferry","text":"<ul> <li>            Lampung Road Trip: Perjalanan dari Jakarta ke Bandar Lampung naik Ferry Merak - Bakauheni          </li> </ul>"},{"location":"blog/tags/#tag:finance","title":"finance","text":"<ul> <li>            Succesfool          </li> </ul>"},{"location":"blog/tags/#tag:gatech","title":"gatech","text":"<ul> <li>            Kuliah S2 Computer Science Online di Georgia Institute of Technology          </li> </ul>"},{"location":"blog/tags/#tag:gcp","title":"gcp","text":"<ul> <li>            A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer          </li> <li>            Analyze Jira Issues using BigQuery and Data Studio          </li> </ul>"},{"location":"blog/tags/#tag:gcs","title":"gcs","text":"<ul> <li>            A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer          </li> <li>            Analyze Jira Issues using BigQuery and Data Studio          </li> </ul>"},{"location":"blog/tags/#tag:jira","title":"jira","text":"<ul> <li>            Analyze Jira Issues using BigQuery and Data Studio          </li> </ul>"},{"location":"blog/tags/#tag:journal","title":"journal","text":"<ul> <li>            Succesfool          </li> </ul>"},{"location":"blog/tags/#tag:kuliah","title":"kuliah","text":"<ul> <li>            Kuliah S2 Computer Science Online di Georgia Institute of Technology          </li> </ul>"},{"location":"blog/tags/#tag:lampung","title":"lampung","text":"<ul> <li>            Lampung Road Trip: Perjalanan dari Jakarta ke Bandar Lampung naik Ferry Merak - Bakauheni          </li> </ul>"},{"location":"blog/tags/#tag:merak","title":"merak","text":"<ul> <li>            Lampung Road Trip: Perjalanan dari Jakarta ke Bandar Lampung naik Ferry Merak - Bakauheni          </li> </ul>"},{"location":"blog/tags/#tag:okr","title":"okr","text":"<ul> <li>            Re-learn OKR          </li> </ul>"},{"location":"blog/tags/#tag:s3","title":"s3","text":"<ul> <li>            A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer          </li> </ul>"},{"location":"blog/tags/#tag:star-schema","title":"star-schema","text":"<ul> <li>            Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?          </li> </ul>"},{"location":"blog/tags/#tag:success","title":"success","text":"<ul> <li>            Succesfool          </li> </ul>"},{"location":"blog/tags/#tag:team","title":"team","text":"<ul> <li>            Re-learn OKR          </li> </ul>"},{"location":"blog/tags/#tag:thought","title":"thought","text":"<ul> <li>            Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?          </li> </ul>"},{"location":"blog/tags/#tag:trip","title":"trip","text":"<ul> <li>            Lampung Road Trip: Perjalanan dari Jakarta ke Bandar Lampung naik Ferry Merak - Bakauheni          </li> </ul>"},{"location":"blog/2019/02/09/re-learn-okr/","title":"Re-learn OKR","text":"<p>Once upon a time, my manager introduced me a tool to help me manage the team. I was so green, this was the first time I manage a team so any tool will likely help me. The tool is called OKR, stands for Objective and Key Result. There was not really much introduction done, so I did my homework trying to understand what this is about.</p> <p>I found one article that helps me to understand OKR. I read it. I said to myself \"This is no brainer, I'll just do it, it's super simple...\". Then we drafted our first OKR. Months passed. We felt very few benefit we get from OKR, it's just like simple goal and target setting, with a necessary buzzword to make it viral. Then we went back to simple goal setting with usual SMART framework (Specific, Measurable, Attainable, Realistic, Time Bound).</p> <p>Recently I re-learned OKR, reading a book titled \"Measure What Matters\" by John Doerr, and turns out I implemented it wrong...</p> <p>Here is what I learned.</p> <p></p>","tags":["team","okr"]},{"location":"blog/2019/02/09/re-learn-okr/#focus-drop-things-to-let-you-focus","title":"Focus, drop things to let you focus","text":"<p>The first time we adopted OKR, we put so many things on the team plate, every problem in the world that the team should solve. We have no courage to pick few but important goals that align to company-wide focus. It is recommended to have 3-5 objectives and 3-5 key results for each objective. No more than that.</p>","tags":["team","okr"]},{"location":"blog/2019/02/09/re-learn-okr/#transparency-means-we-have-to-read-a-lot","title":"Transparency means we have to read, a lot","text":"<p>One of OKR promise is, by having transparency, everyone could see each other's OKR and alignment and collaboration will happen. One thing that I was not aware: this means I have to read as much OKR as possible. Not only read it, but understand what does it mean. Are our goals duplicate? Will they depend on my team? Are we working on OKR that is pulling to different direction?</p> <p>Previously I only read my boss' OKR, and boss' boss' OKR, etc. Now I started to read other teams' OKR, starting from my immediate counterpart. I understand that OKR setting weeks means I have to spare some time to read, a lot.</p>","tags":["team","okr"]},{"location":"blog/2019/02/09/re-learn-okr/#track-track-track","title":"Track, track, track","text":"<p>Regularly track how far the team on achieving OKR is what I missed before. Key result are so clear that there's no grey area, no room of doubt whether you achieve it or not. Tracking regularly will help mitigate risk if we found blocker earlier.</p>","tags":["team","okr"]},{"location":"blog/2019/02/09/re-learn-okr/#stretch-goals-need-more-communication-than-you-think","title":"Stretch goals need more communication than you think","text":"<p>Stretch goals might demoralize the team if it is seen as something not realistic. Things I learned from the book is stretch goals need more communication. We need to communicate how it is attainable, how it helps to get us from our comfort zone and push us to re-think how we work. We need to convey the importance. It also helps to tell the team that there's a bigger thing out there.</p>","tags":["team","okr"]},{"location":"blog/2019/02/09/re-learn-okr/#it-is-not-easy-to-adopt-okr","title":"It is not easy to adopt OKR","text":"<p>OKR, or maybe any tool or framework, requires time to implement. It is not easy to master the process. It takes patient, mindfulness. Regular retro on OKR adoption will help to understand we could improve things, or even modify if we need to.</p> <p>I am now accompanied with more knowledge to implement OKR better. I don't know yet whether it will be beneficial for the team. But I am sure that the last time I used it, I used it wrong. I will post more findings as we experiment more!</p> <p>Share on  Share on </p>","tags":["team","okr"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/","title":"A Cheap and Simple Way to Load Files on S3 to BigQuery using Cloud Composer","text":"<p>In this post, I would like to elaborate how I load my date-partitioned Parquet files on S3 to BigQuery using Airflow. I will explain how to do it as cheap as possible. I will also mention technical issue I met along the way so you can save your time. The Airflow being used is managed-service provided by Google Cloud Platform called Cloud Composer.</p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/#aiflow-to-easily-manage-load-tasks","title":"Aiflow to easily manage load tasks","text":"<p>My use case is to load tens or hundreds of tables worth of several years of data. Airflow makes it is easy to manage tasks with this complexity. I have experienced backfilling using ad hoc script in the past. Using ad hoc script was super hard and tedious to check which date the job failed, fix the issue, and rerun failed dates. Airflow makes it easy to check if my backfill is failed on certain date, I can easily view it on Airflow Dashboard, specifically on DAG's Tree View. Failed tasks will have red color.</p> <p></p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/#transfer-s3-files-to-gcs-for-free","title":"Transfer S3 files to GCS for Free","text":"<p>Now I know where my job will run, yet there are some alternatives to copy S3 files to GCS: - Create a machine to download data from S3 and load to GCS - Use big data processing such as Spark to read S3 and load to GCS - Use Storage Transfer Service</p> <p>The cheapest and easiest way to copy file as is is to use the third method, using Storage Transfer Service. It is cheaper because it is free! You don't have to spawn any machines, so you will only incur AWS Out Data Transfer or egress. No cost on GCP beside storage cost. Based on several tries, it is quite fast and also very simple to use.</p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/#how-the-steps-are-tied-together","title":"How the steps are tied together","text":"<p>We are using airflow and Storage Transfer service. But how it fits the bigger picture? Here is the overall flow: <code>S3 --(Storage Transfer Service)--&gt; GCS --(BQ Load)--&gt; BigQuery</code></p> <p>S3 Parquet files will be copied first to GCS. After it is copied completely to GCS, then the files are loaded to BigQuery. I am using <code>S3ToGoogleCloudStorageTransferOperator</code> operator to spawn Storage Transfer Service job. The task will keep waiting until the job finishes. After data loaded to GCS, I am using <code>GoogleCloudStorageToBigQueryOperator</code> operator to load data to BigQuery. The task create a BigQuery load job with specified parameters.</p> <p></p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/#handling-date-partitioned-files","title":"Handling Date-Partitioned Files","text":"<p>A bit more detail on handling date-partitioned files. To handle date-partitioned files, I am using airflow's template variable such as ds. <pre><code>{% raw %}# data partitioned by date\ninclude_prefix = 'my_data/parquet/day_1/my_event/event_date={{ ds }}/part-'\n# bq table partitioned by date\ndestination_table = 'my-gcp-project.mydataset.my_event${{ ds_nodash }}'{% endraw %}\n</code></pre> Variables above are being used to specify which S3 files to copy and to which BigQuery table partition to load. Here is how the variable is being used in S3 to GCS operator. <pre><code>s3_to_gcs = S3ToGoogleCloudStorageTransferOperator(\n    ...\n    object_conditions={ 'include_prefixes': [ include_prefix ] },\n    ...\n)\n</code></pre> And here is how the variable is being used in GCS to BigQuery load operator. <pre><code>gcs_to_bq = GoogleCloudStorageToBigQueryOperator(\n    ...\n    source_objects=[ include_prefix + '*' ],\n    destination_project_dataset_table=destination_table,\n    ...\n)\n</code></pre></p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/#issues-found-during-the-implementation","title":"Issues found during the implementation","text":"<p>The only issue I found was insufficient access for Storage Transfer Service to write to GCS. It was solved by adding a bucket policy which assign Storage Transfer\u2019s service account a Storage Legacy Writer role. You can find the detail here https://cloud.google.com/storage-transfer/docs/configure-access#sink. It was not really clear when I read the storage transfer overview documentation.</p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/22/a-cheap-and-simple-way-to-load-files-on-s3-to-bigquery-using-cloud-composer/#full-code-example","title":"Full code example","text":"<p>You can find example of the dag here https://github.com/rendybjunior/cloud-composer-examples</p> <p>Feel free to comment if you have any issues on your implementation.</p> <p>Share on  Share on </p>","tags":["airflow","composer","gcp","bigquery","gcs","s3"]},{"location":"blog/2019/06/30/analyze-jira-issues-using-bigquery-and-data-studio/","title":"Analyze Jira Issues using BigQuery and Data Studio","text":"<p>This post is started from my frustation trying to analyze Jira issues using Jira report features. Jira provides built-in reports, for example if you have a Kanban board it will provide Control Chart. However, if you want to customize the insight, the only way that I find is by doing a lot of coding, which is not flexible enough for me to do ad hoc analysis. I ended up copying Jira issue to BigQuery so that I can analyze easily.</p>","tags":["jira","airflow","composer","gcp","bigquery","gcs"]},{"location":"blog/2019/06/30/analyze-jira-issues-using-bigquery-and-data-studio/#using-jira-api-to-get-jira-issues","title":"Using Jira API to Get Jira Issues","text":"<p>I am using Python JIRA library to do the work. Since I'm going to analyze the data regularly, I schedule a script on Cloud Composer that query Jira data and then upload to BigQuery. The first part is getting API authenticaion detail. You will need server, user, and API key to work with. Here's the sample value: <pre><code>jira_user = 'mrawesome@abcd.com'\njira_apikey = 'xxx'\njira_server = 'https://abcd.atlassian.net/'\n</code></pre> Then, we need to design how the JQL query will be. JQL, stands for Jira Query Language, is a query language we will use to get issues from Jira API. I am planning run this script daily, take all issues created on yesterday's date in project ABCD. Here's my JQL example using hardcoded date. <pre><code>jql = 'project = \"ABCD\" AND created &gt;= \"2019/06/28\" AND created &lt; \"2019/06/29\"'\n</code></pre> Since I am going to load it into BigQuery, I write it first as json file locally. Here's how the complete script looks like. <pre><code>import os, json, copy\nfrom jira import JIRA\n\njira_user = 'mrawesome@abcd.com'\njira_apikey = 'xxx'\njira_server = 'https://abcd.atlassian.net/'\njql = 'project = \"ABCD\" AND created &gt;= \"2019/06/28\" AND created &lt; \"2019/06/29\"'\ntemp_file_name = 'jira_created_2019-06-28.json'\nprefix = 'jira_created/created=2019-06-28/'\n\njira = JIRA({'server': jira_server}, basic_auth=(jira_user, jira_apikey))\nwith open(temp_file_name, 'w') as fp:\n    for issue in jira.search_issues(jql,maxResults=max_result):\n        fp.write(json.dumps(issue.raw))\n        fp.write(\"\\n\")\n</code></pre></p>","tags":["jira","airflow","composer","gcp","bigquery","gcs"]},{"location":"blog/2019/06/30/analyze-jira-issues-using-bigquery-and-data-studio/#oops-need-to-cleanse-the-data","title":"Oops, Need to Cleanse the Data","text":"<p>After my first run on the script, I naively tried to load it into BigQuery via web UI, and I got some details to be cleansed: - The query return ten thousands of custom fields, custom fields are fields defined by JIRA users. I need to exclude them as I'm not using them - Object returned contains fields started with number, which is avatar fields: '16x16', '32x32', etc. Need to exclude them as well. - The date returned is using ISO date time with letter 'T' to separate date and time, BigQuery refuse to process and say that we need to use space as date and time separator Then I created some functions to do those clean up and transformation before I write the issues to JSON.</p>","tags":["jira","airflow","composer","gcp","bigquery","gcs"]},{"location":"blog/2019/06/30/analyze-jira-issues-using-bigquery-and-data-studio/#upload-to-gcs-and-load-to-bigquery","title":"Upload to GCS and Load to BigQuery","text":"<p>As it involves several steps already that should be decoupled, I decided to use Composer. Here's how the DAG looks like. <pre><code>with DAG(dag_id, schedule_interval=schedule_interval,\n        default_args=default_args) as dag:\n\n  jira_to_gcs = PythonOperator(\n    task_id='jira_to_gcs',\n    python_callable=jira_to_gcs,\n    op_kwargs={'bucket_name': gcs_bucket},\n    provide_context=True\n  )\n\n  gcs_to_bq = GoogleCloudStorageToBigQueryOperator(\n    task_id='gcs_to_bq',\n    bucket=gcs_bucket,\n    source_objects=[ 'jira_created/created={{ ds }}/*.json' ],\n    destination_project_dataset_table=destination_table_with_partition,\n    source_format=source_format,\n    create_disposition='CREATE_IF_NEEDED',\n    write_disposition='WRITE_TRUNCATE'\n  )\n</code></pre></p>","tags":["jira","airflow","composer","gcp","bigquery","gcs"]},{"location":"blog/2019/06/30/analyze-jira-issues-using-bigquery-and-data-studio/#finally-time-to-analyze-the-data","title":"Finally, Time to Analyze the Data!","text":"<p>After several months backfill in several minutes only, we are ready to analyze the data on BigQuery. Start with a simple one, how's the trend for issue based on priority? The query was only 5.3KB, which translate to almost $0 with $5 per TB current BigQuery query pricing.</p> Jira Issues on BigQuery <p>After this simple initial query, I clicked \"EXPLORE WITH DATA STUDIO\" on red circle above.</p> Jira Issues on Data Studio <p>I am so happy now I can easily create my own insight and create my own queries to dig deeper on my Jira issues. :) Share on  Share on </p>","tags":["jira","airflow","composer","gcp","bigquery","gcs"]},{"location":"blog/2019/07/14/connecting-the-dots-data-in-event-sourcing-and-dimensional-modeling-how-close-are-they/","title":"Connecting the Dots, Data in Event Sourcing and Dimensional Modeling, How Close are They?","text":"<p>Working on both event sourcing and dimensional modeling, looking at the concept and understanding some use cases, I feel they are somehow similar. They both care about state changes, not the state itself. This makes me wonder, how close are they actually, can they work together in a, let say, hypothetical use case?</p> <p>Let's start the thought process with a simple case: an online book store. The online book store allows you to order a book, proceed to checkout, fill payment details, and then the book will be delivered to you. To simplify the case, I won't use cart concept, only one book per order. Let say I have a service to handle the states of the book order, starting from ordered, paid, and delivered.</p>","tags":["thought","event-sourcing","data-modeling","dimensonal-modeling","star-schema","architecture"]},{"location":"blog/2019/07/14/connecting-the-dots-data-in-event-sourcing-and-dimensional-modeling-how-close-are-they/#event-sourcing-design-of-the-online-book-store","title":"Event Sourcing Design of the Online Book Store","text":"<p>It would be overkill to design event sourcing for this case of course, but let say we design the events, how the design will look like? Quoting Martin Fowler, Event Sourcing [1]:</p> <p>ensures that all changes to application state are stored as a sequence of events</p> <p>Using event sourcing concept, instead of only storing the latest state of book order, I will store the state changes. This means, for the case above, I'll store several events: <code>Order Event</code>, <code>Pay Success Event</code>, and <code>Deliver Event</code>. Let's not go to infrastructure detail, let say I store it somewhere and apply state changes by subscribing to the events accordingly.</p> <p>Here's the state I'll store for customer to see their current order status.</p> Order Table <p>And here's the events I will store in order to be able to replay the state, if I need to.</p> Events","tags":["thought","event-sourcing","data-modeling","dimensonal-modeling","star-schema","architecture"]},{"location":"blog/2019/07/14/connecting-the-dots-data-in-event-sourcing-and-dimensional-modeling-how-close-are-they/#dimensional-model-design-of-the-online-book-store","title":"Dimensional Model Design of the Online Book Store","text":"<p>Now, what about dimensional model of the use case? Before we go into the design, here are dimensional modeling steps suggested by Kimball [2]: 1. Select business process 2. Decide granularity 3. Identify dimension 4. Identify facts and measures</p> <p>To make things clearer to the use case, I'll pick one simple business question to test whether the dimensional model fit the purpose:</p> <p>I want to see daily count of books sold for the last 3 months grouped by book category</p> <p>Let say, the definition of sales is when the payment is succeed. Then, the sales business process will use payment data, in combination with order data to get more context on what actually being paid.</p> <ol> <li>Select business process: Sales</li> <li>Decide granularity: Order Item because I need book category. However, as only one book allowed per order, order item grain = sales grain</li> <li>Identify dimension: Book category, date</li> <li>Identify facts and measures: Book quantity</li> </ol> <p>See simplified dimensional design below (assume dim book is using SCD type 1, overwrite only latest state):</p> Fact and Dimension <p>The query to answer business question above will be: <pre><code>SELECT\n  sales_date,\n  dim_book.category,\n  SUM(quantity)\nFROM\n  fact_sales JOIN dim_book ON fact_sales.book_id = dim_book.book_id\nWHERE\n  sales_date &gt; DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH)\nGROUP BY 1, 2\n</code></pre></p>","tags":["thought","event-sourcing","data-modeling","dimensonal-modeling","star-schema","architecture"]},{"location":"blog/2019/07/14/connecting-the-dots-data-in-event-sourcing-and-dimensional-modeling-how-close-are-they/#so-how-close","title":"So... How close?","text":"<p>Assuming I'm building a dimensional model data from event sourcing data, from the example above, there are several things that I can conclude: * They both care about events, hence storing all events will make dimensional modeling a lot easier, as opposed to using change data capture or guessing state changes from the latest state in database. * I might need to join data from several events in order to get dimensional model I want. In the example above, Pay Success Event is the definiton of sales, but it does not care about book detail. So I have to join <code>Pay Success Event</code> and <code>Order Event</code> in order to get Fact Sales table * Not covered in the example above, but building a dimension table will need some events as well, such as <code>Add Book Event</code>.</p> <p>Yet, this is hypothetical case only, the devils are in the details. Let me know if you see the conclusion otherwise, or you see my understanding of the concept is not accurate.</p>","tags":["thought","event-sourcing","data-modeling","dimensonal-modeling","star-schema","architecture"]},{"location":"blog/2019/07/14/connecting-the-dots-data-in-event-sourcing-and-dimensional-modeling-how-close-are-they/#references","title":"References","text":"<ul> <li>[1] https://martinfowler.com/eaaDev/EventSourcing.html</li> <li>[2] https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/four-4-step-design-process/ Share on  Share on </li> </ul>","tags":["thought","event-sourcing","data-modeling","dimensonal-modeling","star-schema","architecture"]},{"location":"blog/2019/08/08/lampung-road-trip-perjalanan-dari-jakarta-ke-bandar-lampung-naik-ferry-merak---bakauheni/","title":"Lampung Road Trip: Perjalanan dari Jakarta ke Bandar Lampung naik Ferry Merak - Bakauheni","text":"<p>Rosi, istri saya, berkali-kali mengajak ke Lampung untuk melihat keindahan Pulau Pahawang. Diajaknya saya naik kapal ferry dari Merak ke Bakauheni. Saya menolak berkali-kali karena kurang nyaman untuk naik kapal ferry (kurang nyaman = ga berani). Namun saya iyakan juga, saya memberanikan diri. Cikaracak ninggang batu, laun-laun jadi legok. Karena terus menurus dirayu, akhirnya luluh juga.</p> <p>Kami menghabiskan 5 hari di sana, tepatnya tanggal 1-5 Agustus 2019. Kami berangkat bersama satu keluarga lainnya, temannya Rosi. Kami sudah pernah trip bersama sebelumnya ke Lombok, sudah sama-sama cocok. Perjalanan dua keluarga membuat biaya lebih murah, misal untuk kapal ferry yang hanya dihitung per mobil, tiga atau enam penumpang dihitung sama.</p> <p>Hari pertama, Kamis 1 Agustus kami awali dengan menyebrang Selat Sunda. Pada pukul 16.00 WIB saya dijemput dari kantor, kemudian kami berangkat ke pelabuhan Merak. Perjalanan dari Jakarta ke Merak menghabiskan waktu sekitar 2 jam lebih. Kami sampai di pelabuhan jam 7 karena diperjalanan ada istirahat makan dan shalat.</p> <p>Kami mengalami hambatan di pintu masuk dermaga karena tiket harus dibeli menggunakan e-money, sedangkan saldo kami tidak cukup. Saat itu harga tiket untuk mobil penumpang adalah 579 ribu, jumlah saldo yang jarang siap dipakai di e-money. Penumpang tidak tambah bayar lagi, tiket dihitung per mobil. KTP juga peru disiapkan untuk data penumpang; satu KTP saja cukup untuk perwakilan.</p> <p>Terlepas dari masalah top-up e-money, menurut saya naik ferry jauh lebih sederhana dibandingkan dengan naik pesawat terbang. Mirip sekali dengan masuk pusat perbelanjaan; masuk dengan e-money (dan KTP), parkirkan mobil di dalam kapal, naik tangga ke lantai penumpang, lalu duduk manis. Saya perkirakan total waktu dari masuk portal hingga duduk di atas kapal tidak lebih dari 5 menit. Kapal tersedia hampir setiap jam, sehingga jam berapapun datang, tinggal naik dan kapal akan berangkat pada jam terdekat. Karena kesederhanaan ini saya jadi tertarik untuk melakukan perjalanan darat kembali ke lokasi lain di Pulau Sumatera.</p> <p>Pertama kali menaikkan mobil ke ferry merupakan pengalaman mendebarkan bagi saya. Naiknya cukup terjal dan belokannya cukup tajam. Penyambung antara dermaga dan kapal bergeser-geser seiring dengan bergoyangnya kapal. Namun geserannya kecil sekali sehingga tidak membahayakan.</p> Ilustrasi. Foto kami naik ferry di Bakauheni saat kembali <p>Kapal ferry kami, kalau tidak salah namanya KMP Port Link, berangkat jam 8 lebih sedikit. Kesan mula saya tentang kapal ferry berubah total saat naik ke lantai penumpang. Tempatnya nyaman dan luas sekali, bahkan ada tempat bermain anak. Goyangan yang saya khawatirkan hampir tidak terasa, mungkin karena kapalnya cukup besar. Kesannya mirip naik kereta, bahkan lebih baik karena luas sehingga anak-anak bebas berlarian kesana kemari.</p> <p>Kami tiba di Bakauheni sekitar pukul setengah sepuluh. Keluar kapal sesederhana naik ke kapal. Perjalanan kami lanjutkan dengan melewati tol sekitar 90 km. Dalam satu jam setengah, kami sudah tiba di Bandar Lampung dan check-in di hotel yang kami tuju. Kami mendapatkan hotel dengan harga sekitar 150 ribu per malam; itu sudah mendapatkan fasilitas AC dan air panas. Karena cocok dengan hotelnya, kami perpanjang hingga esok hari.</p> <p>Total perjalanan dari Jakarta ke Bandar Lampung sekitar 7 jam, hampir tidak ada hambatan selain macet di tol arah Tangerang. Menyetir 7 jam pun tidak berasa melelahkan karena ada istirahat 1 jam lebih di atas kapal. Sangat layak untuk dipertimbangkan bagi penduduk Jakarta dan sekitarnya sebagai alternatif tujuan wisata.</p> <p>Share on  Share on </p>","tags":["trip","lampung","ferry","bakauheni","merak"]},{"location":"blog/2019/08/10/succesfool/","title":"Succesfool","text":"<p>Successfool. Istilah yang pertama kali saya baca dari situs theminimalists.com. Istilah ini merepresentasikan kesuksesan fana, di mana sukses adalah mewujudkan impian kebanyakan orang, mencapai situasi yang didambakan banyak orang, mencapai status sosial tertentu.</p> <p>Sejak kecil, yang saya tahu sukses adalah kepemilikan material yang mewah; punya rumah besar, mobil mewah, tanah luas, perhiasan banyak, dan lain-lain. Sukses adalah bergaji besar, punya jabatan bergengsi, dan punya gelar setinggi-tingginya. Sukses adalah sudah menikah, punya anak minimal dua, harus ada laki-laki dan perempuan. Sukses adalah liburan ke berbagai tempat eksotis. Setidaknya itu tekanan sosial yang saya pribadi rasakan dari keluarga, orangtua, dan sanak saudara. Topik pertanyaan saat silaturahmi tahunan di hari yang fitri tidak jauh dari pertanyaan-pertanyaan tersebut.</p> Gambar random, biar ga tulisan semua. <p>Apakah hidup tanpa hal-hal di atas artinya tidak sukses? Saya baru tahu setelah cukup dewasa, kalau jawaban dari pertanyaan tersebut adalah: belum tentu. Ternyata sukses bagi saya itu ketika saya bisa berkontribusi kepada sesama. Semakin besar kontribusi saya, saya merasa semakin sukses. Hal lain yang saya rasakan, ketika saya fokus untuk memberikan apa yang terbaik sebagai kontribusi, materi akan mengikuti.</p> <p>Menurut saya kecukupan finansial itu penting sekali, karena dengan kecukupan finansial kita bisa memilih. Misalnya, kita bisa memilih apakah kita mau mendaftarkan anak untuk les Bahasa Inggris atau tidak, atau memilih sekolah yang cukup bagus. Bila secara finansial kita kurang, tentu kita tidak punya pilihan tersebut. Namun, bukan berarti finansial dan materi perlu jadi tujuan utama, jadi fokus kita, jadi definisi utama kesuksesan.</p> <p>Dengan menjadikan materi sebagai definisi utama kesuksesan, kita membangun masyarakat yang berorientasi materi. Silaturahmi jadi ajang pamer. Hari-hari dipenuhi dengan pikiran bagaimana caranya mendapatkan uang untuk memperbarui apa yang sudah dimiliki sekarang. Diskusi dipenuhi dengan apa perbaharuan yang harus kita miliki berikutnya; rumah baru, mobil baru, smartphone canggih, dan seterusnya. Sungguh sayang bila waktu hidup kita yang singkat dihabiskan untuk mengejar materi yang tidak ada habisnya. Alangkah indahnya apabila kita bangun pagi dengan semangat yang berbeda, semangat berkontribusi kepada sesama.</p> <p>Dulu, saya kira dengan mendapatkan materi saya akan bahagia. Namun ternyata saya salah. Setelah mendapatkan apa yang saya inginkan, saya sering merasa kosong. Kok, perasaan yang bahagia yang saya cari, tidak kunjung saya dapatkan. Malah seringkali apa yang saya beli malah membuat saya tidak bahagia. Kadang saya merasa membuat-buat hidup saya untuk terlihat lebih sukses dari yang sebenarnya, sampai-sampai saya benci dengan diri saya sendiri. Tidak ada salahnya punya barang-barang yang memberikan nilai ke dalam hidup kita. Yang kurang tepat adalah menjadikan barang-barang tersebut sebagai pusat dari kehidupan kita. Membeli yang kita inginkan, lebih dari apa yang kita butuhkan. Sejauh yang saya alami, kebahagiaan hakiki datang bukan dari materi, tapi dari rasa syukur, dari orang-orang di sekitar kita.</p> Kebahagiaan hqq. <p>Saya mencoba berpikir, dari mana sebenarnya tekanan sosial ini datang. Apakah karena kita terus diserang gambaran kesuksesan yang ditampilkan oleh acara di televisi melalui sinetron dan kehidupan sehari-hari artis, atau di jaman sekarang diwakili oleh publikasi akun selebriti di media sosial seperti selebgram, yang menampilkan kehidupannya yang serba indah. Entahlah, sampai sekarang saya belum punya jawabannya. Mungkin keinginan punya materi yang lebih merupakan intuisi kita untuk bertahan hidup, yang sayangnya teramplifikasi oleh ekspektasi sosial yang berlebihan melalui tekanan sosial dalam berbagai media seperti media sosial.</p> <p>Apapun alasannya, sudah waktunya kita, terutama generasi milenial sebagai generasi di usia produktif, untuk berpikir: apa arti sukses bagi kita? Perlukah kita memperlihatkan kecukupan materi kita kepada orang lain? Adakah yang lebih penting dari itu? Apa yang memberi kita kebahagiaan yang hakiki? Share on  Share on </p>","tags":["journal","success","finance"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/","title":"Kuliah S2 Computer Science Online di Georgia Institute of Technology","text":"<p>Selepas lulus kuliah di tahun 2013, saya menyimpan keinginan untuk kuliah ke luar negeri. Tujuannya untuk memperluas wawasan serta koneksi. Salah satu negara tujuan utama adalah Amerika Serikat; alasannya karena banyak perusahaan teknologi besar yang lahir di sana. Namun, keinginan tersebut urung terlaksanakan karena ada urusan keluarga yang menyebabkan saya tidak bisa jauh dari kampung halaman.</p> <p>Maju ke tahun 2019, saya punya kolega kerja yang kuliah online sambil bekerja. Saya pun tanya-tanya; kuliah di mana, kualitasnya bagaimana, biayanya berapa, bagaimana membagi waktunya, kesannya bagaimana sejauh ini, dan lain-lain. InsyaAllah blog post ini menjawab pertanyaan tersebut dengan detail sebagai referensi dan gambaran bagi teman-teman pembaca. Saat tulisan ini dibuat, saya sedang berada di akhir semester ke-dua saya.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#kualitas-program-studi-omscs","title":"Kualitas Program Studi OMSCS","text":"<p>Saya tanya kuliah di mana, teman saya menjawab Georgia Institute of Technology, disingkat Georgia Tech, kampus yang sejujurnya belum pernah saya dengar sebelumnya. Program studinya adalah Online Master of Science in Computer Science atau disingkat OMSCS. Karena saya belum pernah dengar sebelumnya, pertanyaan berikutnya adalah bagaimana kualitas program studinya. Teman saya menjawab kalau kualitasnya bagus, beberapa mata kuliah relatif mendalam dan sulit. Biasanya kalau kuliahnya susah, belajarnya banyak, berdasarkan pengalaman pribadi jungkir balik di ITB :P . Saya pun meriset program studinya dan mendapatkan bahwa di 2018 Georgia Tech College of Computing -- tempat OMSCS bernaung -- mendapatkan urutan #8 program studi CS graduate terbaik di US versi U.S. News, serta urutan #7 di kategori Artificial Intelligence.</p> Georgia Tech <p>Pada dua semester awal, saya mengambil mata kuliah Knowledge-based Artificial Intelligence (KBAI) dan Educational Technology (EdTech). Berdasarkan pengalaman di dua mata kuliah ini, saya merasa belajar banyak hal yang membuat saya menyimpulkan kualitas program studinya (atau setidaknya dua kuliah ini) memang benar bagus. Saya merasakan bahwa mahasiswa tidak dicekoki ilmu untuk dihafalkan lalu diujikan. Contohnya, pada kuliah KBAI, ujian hanya 20% dari nilai akhir. Sisanya adalah tugas di mana mahasiswa diajak berpikir mengaplikasikan ilmu dan meriset beberapa isu yang relevan dengan pengaplikasian ilmunya. Misalnya, salah satu tugas saya adalah meneliti isu data privacy dan bagaimana mengimplementasikan AI yang tetap menghormati privasi data pengguna. Contoh lainnya, pada kuliah EdTech, mahasiswa dibebaskan melakukan riset, membuat konten edukasi, atau membangun software terkait dunia edukasi. Setiap mahasiswa diberi fondasi apa itu edukasi, pedagogi, dan pengaplikasian teknologi dalam dunia edukasi. Setelah diberi fondasi, mahasiswa dibebaskan mengeksplor. Setiap mahasiswa diberi seorang mentor untuk mengarahkan. Dalam mata kuliah ini saya membuat game untuk mengedukasi cara membedakan berita hoax (lihat di sini untuk bermain).</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#kenapa-kuliah-online","title":"Kenapa Kuliah Online","text":"<p>Karena saya tidak bisa kuliah di luar dengan berbagai faktor, kuliah online jadi solusinya. Online bukan berarti tidak berkualitas. Kalau kita bisa memilih tempat yang berkualitas kenapa tidak, apalagi kalau salah satu program studi top di bidangnya. Setelah berjalan dua semester, saya pun merasakan manfaat lain kuliah selain fleksibilitas tempat, yaitu fleksibilitas waktu. Saya bisa menonton materi kapan saja tanpa terbatas oleh jadwal, seringkali saya menonton kuliah sambil berangkat atau pulang kerja di KRL. Saya juga tidak harus habis waktu ke lokasi kuliah. Ini menjadi solusi sangat menarik bagi saya yang bekerja full-time dan sudah punya dua anak. Membagi waktu dengan keluarga dan pekerjaan itu menjadi sangat penting.</p> <p>Tulisan ini saya buat ditengah pandemik Covid-19 karena saya merasa ini semakin relevan dengan adanya pandemik ini. OMSCS didesain dari awal online, sehingga sudah sangat siap untuk dijalankan online. Tentu beda dengan yang mendadak online, yang kemungkinan kikuk dalam melakukan transisi dalam beberapa hal (seperti yang saya amati di sekolah anak saya ketika harus mendadak online).</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#biaya-kuliah-di-omscs-georgia-tech","title":"Biaya Kuliah di OMSCS Georgia Tech","text":"<p>Ini hal penting yang harus jelas sekali di awal bagi saya. Saya perlu tahu apakah saya mampu membayarnya sampai saya lulus nanti. Biayanya saya bagi menjadi biaya pendaftaran dan biaya kuliah.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#biaya-persiapan-dan-pendaftaran","title":"Biaya Persiapan dan Pendaftaran","text":"<p>Saya mendaftar di tengah 2019 untuk masuk kuliah di Spring 2020. Sebagian besar biaya digunakan untuk kursus dan ujian TOEFL yang merupakan salah satu syarat masuknya (minimal total skor TOEFL iBT 100, dengan minimal skor 19 di setiap section-nya). Berikut biaya yang saya keluarkan:</p> <ul> <li>Biaya pendaftaran $75, atau sekitar 1,1 juta rupiah</li> <li>Ujian TOEFL $205, atau sekitar 3 juta rupiah</li> <li>Les TOEFL online $90, atau sekitar 1,4 juta rupiah</li> <li>Kirim ijazah S1 dan transkrip yang telah dilegalisir lewat kurir pos (setelah pengumuman diterima), seingat saya 500-600 ribu rupiah</li> </ul> <p>Total semuanya sekitar 6 juta rupiah. Tentu, TOEFL-nya tetap berguna untuk daftar ke kampus lain.</p> <p>Les TOEFL saya ambil karena speaking saya suram. Saya ambil kelas TOEFL online di sini untuk dua bulan (masing-masing $45). Teknologi situsnya sangat outdated, gurunya juga sangat oldschool. Namun gurunya memberi banyak sekali slot untuk berlatih speaking dan dinilai langsung oleh beliau. Komennya pun tajam-tajam dan sangat membangun. Saya rekam jawaban dari pertanyaan TOEFL speaking lalu saya kirim lewat email, beliau balas dalam 1x24 jam dengan nilai estimasi skor beserta feedback apa yang harus diperbaiki.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#biaya-semester","title":"Biaya Semester","text":"<p>Biaya semester saya sama untuk tiga semester terakhir, yaitu Spring 2020, Summer 2020, dan Fall 2020. Di setiap semester, saya membayar tiga komponen di bawah dengan total $841 atau sekitar 12,6 juta rupiah.</p> <ul> <li>Special Institutional Fee $194</li> <li>Technology Fee $107</li> <li>Tuition Fee $540</li> </ul> <p>Jika mengambil lebih dari satu mata kuliah, tebakan saya yang naik hanya Tuition Fee saja, dikali dengan jumlah mata kuliah yang diambil. Untuk sampai lulus, kita perlu menyelesaikan 10 mata kuliah. Kalau ambil satu mata kuliah per semester seperti saya, total sampai lulus perkiraannya sekitar 126 juta rupiah (dengan asumsi nilai tukar stabil).</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#apakah-mahal","title":"Apakah Mahal","text":"<p>Mahal itu relatif. Sebagai ilustrasi, program studi S2 Ilmu Komputer di UI biayanya 14 sampai 16 juta per semester, dengan uang pangkal 17 juta (sumber di sini). Kalau dibandingkan tentu OMSCS lebih murah. Namun, worth it atau tidaknya bergantung pada pendapat masing-masing orang, serta preferensinya. Saya sarankan Anda untuk mempertimbangkan dengan tujuan belajar, apa yang ingin dicapai, serta perbedaan dari alternatif yang mungkin anda ambil (kuliah di berbagai tempat, ambil beasiswa, atau tidak kuliah sama sekali). Oh ya, beasiswa ada juga namun saya belum mencari tahu lebih dalam terkait persyaratan dan yang lainnya.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#dapatkah-wawasan-dan-koneksi","title":"Dapatkah Wawasan dan Koneksi","text":"<p>Kuliah online di kampus luar negeri tentu sangat berbeda dengan kuliah di luar negeri langsung. Kalau saya dengar cerita teman-teman saya, ia banyak melakukan meet up dan membangun wawasan serta koneksi dengan cara tersebut. Untuk koneksi, sejauh ini saya merasakan hal itu belum tercapai. Kuliah online membuat segalanya lebih mudah jika kita individualistik. Misal, di kelas EdTech saya lebih memilih kerja sendiri dibanding harus membuat kelompok. Tentu akan sangat menantang untuk bekerjasama tanpa bertemu tatap muka, apalagi jika ada di beda timezone. Untuk wawasan, saya merasa belajar banyak seperti yang telah saya paparkan di dua mata kuliah yang sudah saya lalui.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#mudahkah-mendaftarnya","title":"Mudahkah Mendaftarnya","text":"<p>Saya lupa-lupa ingat apa saja yang saya siapkan, yang paling ribet (sehingga saya tidak lupa) adalah TOEFL. Seingat saya antara lain:</p> <ul> <li>TOEFL minimal skor 100, dan skor 19 di masing-masing section.</li> <li>Surat referensi dari tiga orang, bisa dari dosen atau atasan di tempat kerja. Saya pilih tiga-tiganya atasan di tempat kerja karena dosen saya berhalangan.</li> <li>Surat yang isinya motivasi kita kuliah dan kenapa kita pantas diterima (namanya apa ya, motivation letter?).</li> <li>Administration stuff, seperti ijazah dan transkrip yang dilegalisir.</li> </ul> <p>Tidak ada persyaratan ujian GRE seperti program studi CS di US pada umumnya.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#bagaimana-membagi-waktu","title":"Bagaimana Membagi Waktu","text":"<p>Untuk membagi waktu antara kerja, keluarga, dan kuliah, saya coba konsisten setiap subuh mengerjakan tugas. Jika tidak cukup, maka dikerjakan di akhir minggu. Setiap mata kuliah beda bebannya per minggu. Website review mata kuliah di OMSCS beserta estimasi workload mingguan memberikan gambaran sehingga saya bisa memilih mata kuliah apa yang akan saya ambil semester ini berdasarkan banyaknya pekerjaan dan rencana keluarga. Sejauh ini kurang lebih saya menghabiskan waktu 15 jam per minggu.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#penutup","title":"Penutup","text":"<p>Bagi saya, kesempatan untuk belajar di program studi top, dari domisili tinggal, dengan harga yang relatif sama dengan program studi dalam negeri, ditambah fleksibilitas waktu, adalah alasan utama saya ingin menulis ini. Menurut saya ini sangat layak untuk dipertimbangkan bagi teman-teman dari Indonesia (sejauh ini orang Indonesia yang saya tahu jadi mahasiswa di sini baru saya dan kolega kerja saya itu). Semoga tulisan ini memberikan sedikit gambaran dan bisa menambah alternatif bila teman-teman pembaca hendak memutuskan melanjutkan sekolah ke jenjang S2.</p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/2020/08/01/kuliah-s2-computer-science-online-di-georgia-institute-of-technology/#pranala-omscs","title":"Pranala OMSCS","text":"<ul> <li>Website OMSCS GaTech</li> <li>Website review mata kuliah di OMSCS beserta estimasi workload mingguan</li> <li>Twitter resmi OMSCS</li> <li>Selain OMSCS ada juga OMS Analytics</li> </ul> <p>Share on  Share on </p>","tags":["kuliah","computer science","gatech"]},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/archive/2019/","title":"2019","text":""},{"location":"blog/category/journal/","title":"Journal","text":""},{"location":"blog/category/trip/","title":"Trip","text":""},{"location":"blog/category/data/","title":"Data","text":""},{"location":"blog/category/management/","title":"Management","text":""}]}